# Tech Challenge - Pipeline de Dados Bovespa (Fase 2)

Este projeto implementa um pipeline de dados fim-a-fim para extra√ß√£o, processamento e an√°lise de ativos da B3 (PETR4 e BOVA11).

## üöÄ Arquitetura da Solu√ß√£o
A solu√ß√£o utiliza uma arquitetura de Data Lake na AWS dividida em camadas:
- **Extra√ß√£o**: Script Python (`yfinance`) com tratamento de precis√£o de timestamps para compatibilidade Spark.
- **Armazenamento**: AWS S3 nas camadas `raw/` (dados brutos particionados) e `refined/` (dados processados).
- **Processamento**: AWS Glue Job utilizando PySpark para transforma√ß√µes e c√°lculo de m√©dia m√≥vel.
- **Cat√°logo**: AWS Glue Crawler para automa√ß√£o do schema no Data Catalog.
- **Consumo**: Amazon Athena para consultas anal√≠ticas via SQL.

## üõ†Ô∏è Tecnologias Utilizadas
- Python (yfinance, Pandas, Boto3)
- Apache Spark (PySpark)
- AWS Glue, S3, Athena e IAM

## üìà Transforma√ß√µes Implementadas
- Normaliza√ß√£o de nomes de colunas.
- Tratamento de tipos de dados (Timestamps).
- C√°lculo da **M√©dia M√≥vel de 7 dias** para an√°lise de tend√™ncia.
- Particionamento f√≠sico dos dados por Ticker e Data para otimiza√ß√£o de performance e custo.
